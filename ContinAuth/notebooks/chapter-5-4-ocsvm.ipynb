{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# OCSVM Baseline Model\n",
    "*Created by Holger Buech, Q1/2019*\n",
    "\n",
    "**Description**   \n",
    "\n",
    "Reimplemenation of a OCSVM approach to Continuous Authentication described by [1]. Used as baseline model for futher experiments.\n",
    "\n",
    "**Purpose**\n",
    "\n",
    "- Get basic idea about authentication performance using raw data\n",
    "- Verify results of [1]\n",
    "\n",
    "**Data Sources**   \n",
    "\n",
    "- [H-MOG Dataset](http://www.cs.wm.edu/~qyang/hmog.html)  \n",
    "  (Downloaded beforehand using  [./src/data/make_dataset.py](./src/data/make_dataset.py), stored in [./data/external/hmog_dataset/](./data/external/hmog_dataset/) and converted to [./data/processed/hmog_dataset.hdf5](./data/processed/hmog_dataset.hdf5))\n",
    "\n",
    "**References**   \n",
    "\n",
    "[1] Centeno, M. P. et al. (2018): Mobile Based Continuous Authentication Using Deep Features. Proceedings of the 2^nd International Workshop on Embedded and Mobile Deep Learning (EMDL), 2018, 19-24.\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "**1 - [Preparations](#1)**  \n",
    "1.1 - [Imports](#1.1)  \n",
    "1.2 - [Configuration](#1.2)  \n",
    "1.3 - [Experiment Parameters](#1.3)  \n",
    "1.4 - [Select Approach](#1.4)  \n",
    "\n",
    "**2 - [Data Preparations](#2)**  \n",
    "2.1 - [Load Dataset](#2.1)  \n",
    "2.2 - [Normalize Features (if global)](#2.2)  \n",
    "2.3 - [Split Dataset for Valid/Test](#2.3)  \n",
    "2.4 - [Check Splits](#2.4)  \n",
    "2.5 - [Reshape Features](#2.5)  \n",
    "\n",
    "**3 - [Hyperparameter Optimization](#3)**  \n",
    "3.1 - [Load cached Data](#3.1)   \n",
    "3.2 - [Search for Parameters](#3.2)   \n",
    "3.3 - [Inspect Search Results](#3.3)  \n",
    "\n",
    "**4 - [Testing](#4)**   \n",
    "4.1 - [Load cached Data](#4.1)    \n",
    "4.2 - [Evaluate Authentication Performance](#4.2)  \n",
    "4.3 - [Evaluate increasing Training Set Size (Training Delay)](#4.3)  \n",
    "4.4 - [Evaluate increasing Test Set Size (Detection Delay)](#4.4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 1. Preparations <a id='1'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Imports <a id='1.1'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# restore session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chapter-4-5-1-ocsvm-parameter-demo.ipynb\t NOPE WE TRAINING\r\n",
      "chapter-5-2-1-exploration-hmog-statistics.ipynb  output\r\n",
      "chapter-5-4-ocsvm.db\t\t\t\t thesis\r\n",
      "chapter-5-4-ocsvm.ipynb\t\t\t\t thesis-env\r\n",
      "chapter-5-5-siamese-cnn.ipynb\t\t\t utils.ipynb\r\n",
      "chapter-5-6-4-explore-normalization.ipynb\t VAEs - AD .ipynb\r\n",
      "chapter-5-8-final-comparison.ipynb\t\t VAEs.db\r\n",
      "my_path\t\t\t\t\t\t venv\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "#dill.load_session('chapter-5-4-ocsvm.db')\n",
    "dill.dump_session('chapter-5-4-ocsvm.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! virtualenv --python=/usr/bin/python3 venv\n",
    "!source venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "import scipy as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scipy 1.5.2\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/cli/base_command.py\", line 216, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/commands/uninstall.py\", line 90, in run\n",
      "    auto_confirm=options.yes, verbose=self.verbosity > 0,\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/req/req_install.py\", line 684, in uninstall\n",
      "    uninstalled_pathset = UninstallPathSet.from_dist(dist)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/req/req_uninstall.py\", line 535, in from_dist\n",
      "    for path in uninstallation_paths(dist):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/req/req_uninstall.py\", line 67, in unique\n",
      "    for item in fn(*args, **kw):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/req/req_uninstall.py\", line 85, in uninstallation_paths\n",
      "    r = csv.reader(FakeFile(dist.get_metadata_lines('RECORD')))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1432, in get_metadata_lines\n",
      "    return yield_lines(self.get_metadata(name))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1420, in get_metadata\n",
      "    value = self._get(path)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1616, in _get\n",
      "    with open(path, 'rb') as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/lib64/python3.6/site-packages/scipy-1.5.2.dist-info/RECORD'\u001b[0m\n",
      "Found existing installation: numpy 1.19.1\n",
      "Uninstalling numpy-1.19.1:\n",
      "  Successfully uninstalled numpy-1.19.1\n",
      "Collecting numpy==1.16.4\n",
      "  Using cached numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3 MB)\n",
      "\u001b[31mERROR: Error while checking for conflicts. Please file an issue on pip's issue tracker: https://github.com/pypa/pip/issues/new\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3012, in _parsed_pkg_info\n",
      "    return self._pkg_info\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _pkg_info\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 535, in _determine_conflicts\n",
      "    return check_install_conflicts(to_install)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/operations/check.py\", line 108, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/operations/check.py\", line 50, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3032, in _compute_dependencies\n",
      "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3014, in _parsed_pkg_info\n",
      "    metadata = self.get_metadata(self.PKG_INFO)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1420, in get_metadata\n",
      "    value = self._get(path)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1616, in _get\n",
      "    with open(path, 'rb') as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/lib64/python3.6/site-packages/scipy-1.5.2.dist-info/METADATA'\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.19.1\n",
      "Collecting scipy==1.2.1\n",
      "  Using cached scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8 MB)\n",
      "Collecting numpy>=1.8.2\n",
      "  Using cached numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[31mERROR: Error while checking for conflicts. Please file an issue on pip's issue tracker: https://github.com/pypa/pip/issues/new\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3012, in _parsed_pkg_info\n",
      "    return self._pkg_info\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _pkg_info\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 535, in _determine_conflicts\n",
      "    return check_install_conflicts(to_install)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/operations/check.py\", line 108, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_internal/operations/check.py\", line 50, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3032, in _compute_dependencies\n",
      "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3014, in _parsed_pkg_info\n",
      "    metadata = self.get_metadata(self.PKG_INFO)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1420, in get_metadata\n",
      "    value = self._get(path)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1616, in _get\n",
      "    with open(path, 'rb') as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/lib64/python3.6/site-packages/scipy-1.5.2.dist-info/METADATA'\u001b[0m\n",
      "Installing collected packages: numpy, scipy\n",
      "Successfully installed numpy-1.19.1 scipy-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip uninstall scipy --y\n",
    "!python3 -m pip uninstall numpy --y\n",
    "!python3 -m pip install -I numpy==1.16.4\n",
    "!python3 -m pip install -I scipy==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'comb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-50ec37bbeb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneClassSVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/statsmodels/stats/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstattools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdurbin_watson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momni_normtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjarque_bera\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msandwich_covariance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .sandwich_covariance import (\n\u001b[1;32m     28\u001b[0m             \u001b[0mcov_cluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_cluster_2groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_nw_panel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/statsmodels/stats/sandwich_covariance.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouputils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoment_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mse_cov\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m __all__ = ['cov_cluster', 'cov_cluster_2groups', 'cov_hac', 'cov_nw_panel',\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/statsmodels/stats/moment_helpers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'comb'"
     ]
    }
   ],
   "source": [
    "# Standard\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import dataclasses\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "# Extra\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
    "import statsmodels.stats.api as sms\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Custom `DatasetLoader`class for easier loading and subsetting data from the datasets.\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))  # supposed to be parent folder\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.utility.dataset_loader_hdf5 import DatasetLoader\n",
    "\n",
    "# Global utitlity functions are in separate notebook\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configuration <a id='1.2'>&nbsp;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various Settings\n",
    "SEED = 712  # Used for every random function\n",
    "HMOG_HDF5 = Path.cwd().parent / \"data\" / \"processed\" / \"hmog_dataset.hdf5\"\n",
    "EXCLUDE_COLS = [\"sys_time\"]\n",
    "CORES = -1\n",
    "\n",
    "# For plots and CSVs\n",
    "OUTPUT_PATH = Path.cwd() / \"output\" / \"chapter-6-1-3-ocsvm\"\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "REPORT_PATH = Path.cwd().parent / \"reports\" / \"figures\" # Figures for thesis\n",
    "\n",
    "# Plotting\n",
    "%matplotlib inline\n",
    "utils_set_output_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround to remove ugly spacing between progress bars\n",
    "HTML(\"<style>.p-Widget.jp-OutputPrompt.jp-OutputArea-prompt:empty{padding: 0;border: 0;} div.output_subarea{padding:0;}</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Experiment Parameters <a id='1.3'>&nbsp;</a> \n",
    "Selection of parameters set that had been tested in this notebook. Select one of them to reproduce results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class ExperimentParameters:\n",
    "    \"\"\"Contains all relevant parameters to run an experiment.\"\"\"\n",
    "\n",
    "    name: str  # Name of Parameter set. Used as identifier for charts etc.\n",
    "    frequency: int\n",
    "    max_subjects: int\n",
    "    max_test_subjects: int\n",
    "    seconds_per_subject_train: float\n",
    "    seconds_per_subject_test: float\n",
    "    task_types: list  # Limit scenarios to [1, 3, 5] for sitting or [2, 4, 6] for walking, or don't limit (None)\n",
    "    window_size: int  # After resampling\n",
    "    step_width: int  # After resampling\n",
    "    scaler: str  # {\"std\", \"robust\", \"minmax\"}\n",
    "    scaler_scope: str  # {\"subject\", \"session\"}\n",
    "    scaler_global: bool  # fit transform scale on all data (True) or fit on training only (False)\n",
    "    ocsvm_nu: float  # Best value found in random search, used for final model\n",
    "    ocsvm_gamma: float  # Best value found in random search, used for final model\n",
    "    feature_cols: list  # Columns used as features\n",
    "    exclude_subjects: list  # Don't load data from those users\n",
    "        \n",
    "    # Calculated values\n",
    "    def __post_init__(self):\n",
    "        # HDF key of table:\n",
    "        self.table_name = f\"sensors_{self.frequency}hz\"\n",
    "\n",
    "        # Number of samples per _session_ used for training:\n",
    "        self.samples_per_subject_train = math.ceil(\n",
    "            (self.seconds_per_subject_train * 100)\n",
    "            / (100 / self.frequency)\n",
    "            / self.window_size\n",
    "        )\n",
    "\n",
    "        # Number of samples per _session_ used for testing:\n",
    "        self.samples_per_subject_test = math.ceil(\n",
    "            (self.seconds_per_subject_test * 100)\n",
    "            / (100 / self.frequency)\n",
    "            / self.window_size\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "# INSTANCES\n",
    "# ===========================================================\n",
    "\n",
    "# NAIVE_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_MINMAX_OCSVM = ExperimentParameters(\n",
    "    name=\"NAIVE-MINMAX_OCSVM\",\n",
    "    frequency=100,\n",
    "    max_subjects= 40, # 90,\n",
    "    max_test_subjects=15,# 3,\n",
    "    seconds_per_subject_train=67.5,\n",
    "    seconds_per_subject_test=67.5,    \n",
    "    task_types=None,\n",
    "    window_size=50,\n",
    "    step_width=50,\n",
    "    scaler=\"minmax\",\n",
    "    scaler_scope=\"subject\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_nu=0.086,\n",
    "    ocsvm_gamma=0.091,\n",
    "    feature_cols=[\n",
    "        \"acc_x\",\n",
    "        \"acc_y\",\n",
    "        \"acc_z\",\n",
    "        \"gyr_x\",\n",
    "        \"gyr_y\",\n",
    "        \"gyr_z\",\n",
    "        \"mag_x\",\n",
    "        \"mag_y\",\n",
    "        \"mag_z\",\n",
    "    ],\n",
    "    exclude_subjects=[\n",
    "        \"733162\",  # No 24 sessions\n",
    "        \"526319\",  # ^\n",
    "        \"796581\",  # ^\n",
    "        \"539502\",  # Least amount of sensor values\n",
    "        \"219303\",  # ^\n",
    "        \"737973\",  # ^\n",
    "        \"986737\",  # ^\n",
    "        \"256487\",  # Most amount of sensor values\n",
    "        \"389015\",  # ^\n",
    "        \"856401\",  # ^\n",
    "    ],\n",
    ")\n",
    "\n",
    "# VALID_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "VALID_MINMAX_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-MINMAX-OCSVM\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.165,\n",
    "    ocsvm_gamma=0.039,\n",
    ")\n",
    "\n",
    "# NAIVE_ROBUST_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_ROBUST_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"NAIVE-ROBUST-OCSVM\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_nu=0.153,\n",
    "    ocsvm_gamma=0.091,  # below median, selected by chart\n",
    ")\n",
    "\n",
    "# ROBUST_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_ROBUST_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.098,\n",
    "    ocsvm_gamma=0.003,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Select approach <a id='1.4'>&nbsp;</a> \n",
    "Select the parameters to use for current notebook execution here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = VALID_ROBUST_OCSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview of current Experiment Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils_ppp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-28e795a04b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils_ppp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'utils_ppp' is not defined"
     ]
    }
   ],
   "source": [
    "utils_ppp(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 2. Data Preparation <a id='2'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Dataset <a id='2.1'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3d1c6eab6c42ffa2c5d1c9c5f7f0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading sessions', max=960, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hmog = DatasetLoader(\n",
    "    hdf5_file=HMOG_HDF5,\n",
    "    table_name=P.table_name,\n",
    "    max_subjects=P.max_subjects,\n",
    "    task_types=P.task_types,\n",
    "    exclude_subjects=P.exclude_subjects,\n",
    "    exclude_cols=EXCLUDE_COLS,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "hmog.data_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Normalize features (if global) <a id='2.2'>&nbsp;</a> \n",
    "Used here for naive approach (before splitting into test and training sets). Otherwise it's used during generate_pairs() and respects train vs. test borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if P.scaler_global:\n",
    "    print(\"Normalize all data before splitting into train and test sets...\")\n",
    "    hmog.all, _ = utils_custom_scale(\n",
    "        hmog.all,\n",
    "        scale_cols=P.feature_cols,        \n",
    "        feature_cols=P.feature_cols,\n",
    "        scaler_name=P.scaler,\n",
    "        scope=P.scaler_scope,\n",
    "        plot=True,\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipped, normalize after splitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Split Dataset for Valid/Test <a id='2.3'>&nbsp;</a> \n",
    "In two splits: one used during hyperparameter optimization, and one used during testing.\n",
    "\n",
    "The split is done along the subjects: All sessions of a single subject will either be in the validation split or in the testing split, never in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmog.split_train_test(n_test_subjects=P.max_test_subjects)\n",
    "hmog.data_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Check Splits <a id='2.4'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_split_report(hmog.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_split_report(hmog.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 2.5 Reshape Features  <a id='2.5'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reshape & store Set for Validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_valid = utils_reshape_features(\n",
    "    hmog.train,\n",
    "    feature_cols=P.feature_cols,\n",
    "    window_size=P.window_size,\n",
    "    step_width=P.step_width,\n",
    ")\n",
    "\n",
    "# Clean memory\n",
    "del hmog.train\n",
    "# %reset_selective -f hmog.train\n",
    "\n",
    "print(\"Validation data after reshaping:\")\n",
    "display(df_train_valid.head())\n",
    "\n",
    "# Store iterim data\n",
    "df_train_valid.to_msgpack(OUTPUT_PATH / \"df_train_valid.msg\")\n",
    "\n",
    "# Clean memory\n",
    "# %reset_selective -f df_train_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reshape & store Set for Testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test = utils_reshape_features(\n",
    "    hmog.test,\n",
    "    feature_cols=P.feature_cols,\n",
    "    window_size=P.window_size,\n",
    "    step_width=P.step_width,\n",
    ")\n",
    "\n",
    "del hmog.test\n",
    "# %reset_selective -f hmog.test\n",
    "\n",
    "print(\"Testing data after reshaping:\")\n",
    "display(df_train_test.head())\n",
    "\n",
    "# Store iterim data\n",
    "df_train_test.to_msgpack(OUTPUT_PATH / \"df_train_test.msg\")\n",
    "\n",
    "# Clean memory\n",
    "# %reset_selective -f df_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Memory\n",
    "# %reset_selective -f df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 3. Hyperparameter Optimization  <a id='3'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load cached Data <a id='3.1'>&nbsp;</a> \n",
    "Only the split dedicated for hyperparameter optimization is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_valid = pd.read_msgpack(OUTPUT_PATH / \"df_train_valid.msg\")\n",
    "df_train_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Search for Parameters <a id='3.2'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"gamma\": np.logspace(-3, 3), \"nu\": np.linspace(0.0001, 0.3)}\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df_results = None  # Will be filled with randomsearch scores\n",
    "for run in tqdm(range(3)):\n",
    "    for df_cv_scenarios, owner, impostors in tqdm(\n",
    "        utils_generate_cv_scenarios(\n",
    "            df_train_valid,\n",
    "            samples_per_subject_train=P.samples_per_subject_train,\n",
    "            samples_per_subject_test=P.samples_per_subject_test,\n",
    "            seed=SEED + run,\n",
    "            scaler=P.scaler,\n",
    "            scaler_global=P.scaler_global,\n",
    "            scaler_scope=P.scaler_scope,\n",
    "            feature_cols=P.feature_cols,\n",
    "        ),\n",
    "        desc=\"Owner\",\n",
    "        total=df_train_valid[\"subject\"].nunique(),\n",
    "        leave=False,\n",
    "    ):\n",
    "        X = np.array(df_cv_scenarios[\"X\"].values.tolist())\n",
    "        X = X.reshape(X.shape[-3], -1)  # flatten windows\n",
    "        y = df_cv_scenarios[\"label\"].values\n",
    "        train_valid_cv = utils_create_cv_splits(df_cv_scenarios[\"mask\"].values, SEED)\n",
    "        model = OneClassSVM(kernel=\"rbf\")\n",
    "\n",
    "        random_search = RandomizedSearchCV(\n",
    "            model,\n",
    "            param_distributions=param_dist,\n",
    "            cv=train_valid_cv,\n",
    "            n_iter=80,\n",
    "            n_jobs=CORES,\n",
    "            refit=False,\n",
    "            scoring={\"eer\": utils_eer_scorer, \"accuracy\": \"accuracy\"},\n",
    "            verbose=0,\n",
    "            return_train_score=False,\n",
    "            iid=False,\n",
    "            random_state=SEED,\n",
    "        )\n",
    "        random_search.fit(X, y)\n",
    "        df_report = utils_cv_report(random_search, owner, impostors)\n",
    "        df_report[\"run\"] = run\n",
    "        df_results = pd.concat([df_results, df_report], sort=False)\n",
    "\n",
    "df_results.to_csv(OUTPUT_PATH / f\"{P.name}_random_search_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Inspect Search Results <a id='3.3'>&nbsp;</a> \n",
    "**Raw Results & Stats:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(OUTPUT_PATH / f\"{P.name}_random_search_results.csv\")\n",
    "print(\"Example from result table (head):\")\n",
    "display(\n",
    "    df_results[df_results[\"rank_test_eer\"] == 1]\n",
    "    .sort_values(\"mean_test_eer\")\n",
    "    .head(10)\n",
    ")\n",
    "print(\"\\n\\n\\nMost relevant statistics:\")\n",
    "display(\n",
    "    df_results[df_results[\"rank_test_eer\"] == 1][\n",
    "        [\n",
    "            \"mean_fit_time\",\n",
    "            \"param_nu\",\n",
    "            \"param_gamma\",\n",
    "            \"mean_test_accuracy\",\n",
    "            \"std_test_accuracy\",\n",
    "            \"mean_test_eer\",\n",
    "            \"std_test_eer\",\n",
    "        ]\n",
    "    ].describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot parameters of top n of 30 results for every Owner:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_plot_randomsearch_results(df_results, n_top=1)\n",
    "utils_save_plot(plt, REPORT_PATH / f\"buech2019-ocsvm-{P.name.lower()}-parameters.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Using median to select the best parameters, as mean is strongly influenced by outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Memory\n",
    "# %reset_selective -f df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 4. Testing <a id='4'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load cached Data <a id='4.1'>&nbsp;</a> \n",
    "During testing, a split with different users than used for hyperparameter optimization is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test = pd.read_msgpack(OUTPUT_PATH / \"df_train_test.msg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluate Authentication Performance <a id='4.2'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using Testing Split, Scenario Cross Validation, and multiple runs to lower impact of random session/sample selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = None  # Will be filled with cv scores\n",
    "\n",
    "for i in tqdm(range(5), desc=\"Run\", leave=False):  # Run whole test 5 times\n",
    "    for df_cv_scenarios, owner, impostors in tqdm(\n",
    "        utils_generate_cv_scenarios(\n",
    "            df_train_test,\n",
    "            samples_per_subject_train=P.samples_per_subject_train,\n",
    "            samples_per_subject_test=P.samples_per_subject_test,\n",
    "            seed=SEED + i,  # Change seed for different runs\n",
    "            scaler=P.scaler,\n",
    "            scaler_global=P.scaler_global,\n",
    "            scaler_scope=P.scaler_scope,\n",
    "            feature_cols=P.feature_cols,\n",
    "        ),\n",
    "        desc=\"Owner\",\n",
    "        total=df_train_test[\"subject\"].nunique(),\n",
    "        leave=False,\n",
    "    ):\n",
    "        X = np.array(df_cv_scenarios[\"X\"].values.tolist())\n",
    "        X = X.reshape(X.shape[-3], -1)  # flatten windows\n",
    "        y = df_cv_scenarios[\"label\"].values\n",
    "        train_test_cv = utils_create_cv_splits(df_cv_scenarios[\"mask\"].values, SEED)\n",
    "\n",
    "        model = OneClassSVM(kernel=\"rbf\", nu=P.ocsvm_nu, gamma=P.ocsvm_gamma)\n",
    "\n",
    "        scores = cross_validate(\n",
    "            model,\n",
    "            X,\n",
    "            y,\n",
    "            cv=train_test_cv,\n",
    "            scoring={\n",
    "                \"eer\": utils_eer_scorer,\n",
    "                \"accuracy\": \"accuracy\",\n",
    "                \"precision\": \"precision\",\n",
    "                \"recall\": \"recall\",\n",
    "            },\n",
    "            n_jobs=CORES,\n",
    "            verbose=0,\n",
    "            return_train_score=True,\n",
    "        )\n",
    "        df_score = pd.DataFrame(scores)\n",
    "        df_score[\"owner\"] = owner\n",
    "        df_score[\"train_eer\"] = df_score[\"train_eer\"].abs()  # Revert scorer's signflip\n",
    "        df_score[\"test_eer\"] = df_score[\"test_eer\"].abs()\n",
    "        df_results = pd.concat([df_results, df_score], axis=0)\n",
    "\n",
    "df_results.to_csv(OUTPUT_PATH / f\"{P.name}_test_results.csv\", index=False)\n",
    "\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Results from \"EER & Accuracy\" evaluation & prepare for plotting:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(OUTPUT_PATH / f\"{P.name}_test_results.csv\")\n",
    "df_plot = df_results.rename(\n",
    "    columns={\"test_accuracy\": \"Test Accuracy\", \"test_eer\": \"Test EER\", \"owner\": \"Owner\"}\n",
    ").astype({\"Owner\": str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Distribution of Accuracy per subject:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = utils_plot_acc_eer_dist(df_plot, \"Test Accuracy\")\n",
    "utils_save_plot(plt, REPORT_PATH / f\"buech2019-ocsvm-{P.name.lower()}-acc.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = utils_plot_acc_eer_dist(df_plot, \"Test EER\")\n",
    "utils_save_plot(plt, REPORT_PATH / f\"buech2019-ocsvm-{P.name.lower()}-eer.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Evaluate increasing Training Set Size (Training Delay)<a id='4.3'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Testing different amounts of samples in training set\n",
    "- Using Testing Split, Scenario Cross Validation, and multiple runs to lower impact of random session/sample selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_sizes = [2, 4, 6, 8, 20, 60, 120, 180, 250, 350, 500, 750]\n",
    "\n",
    "df_results = None  # Will be filled with cv scores\n",
    "for i in tqdm(range(5), desc=\"Run\", leave=False):\n",
    "    for n_train_samples in tqdm(training_set_sizes, desc=\"Train Size\", leave=False):\n",
    "        for df_cv_scenarios, owner, impostors in tqdm(\n",
    "            utils_generate_cv_scenarios(\n",
    "                df_train_test,\n",
    "                samples_per_subject_train=P.samples_per_subject_train,\n",
    "                samples_per_subject_test=P.samples_per_subject_test,\n",
    "                limit_train_samples=n_train_samples,  # samples overall\n",
    "                seed=SEED + i,  # Change seed for different runs\n",
    "                scaler=P.scaler,\n",
    "                scaler_global=P.scaler_global,\n",
    "                scaler_scope=P.scaler_scope,\n",
    "                feature_cols=P.feature_cols,\n",
    "            ),\n",
    "            desc=\"Owner\",\n",
    "            total=df_train_test[\"subject\"].nunique(),\n",
    "            leave=False,\n",
    "        ):\n",
    "            X = np.array(df_cv_scenarios[\"X\"].values.tolist())\n",
    "            X = X.reshape(X.shape[-3], -1)  # flatten windows\n",
    "            y = df_cv_scenarios[\"label\"].values\n",
    "            train_test_cv = utils_create_cv_splits(df_cv_scenarios[\"mask\"].values, SEED)\n",
    "\n",
    "            model = OneClassSVM(kernel=\"rbf\", nu=P.ocsvm_nu, gamma=P.ocsvm_gamma)\n",
    "\n",
    "            scores = cross_validate(\n",
    "                model,\n",
    "                X,\n",
    "                y,\n",
    "                cv=train_test_cv,\n",
    "                scoring={\"eer\": utils_eer_scorer},\n",
    "                n_jobs=CORES,\n",
    "                verbose=0,\n",
    "                return_train_score=True,\n",
    "            )\n",
    "            df_score = pd.DataFrame(scores)\n",
    "            df_score[\"owner\"] = owner\n",
    "            df_score[\"train_samples\"] = n_train_samples\n",
    "            df_score[\"train_eer\"] = df_score[\n",
    "                \"train_eer\"\n",
    "            ].abs()  # Revert scorer's signflip\n",
    "            df_score[\"test_eer\"] = df_score[\"test_eer\"].abs()\n",
    "            df_results = pd.concat([df_results, df_score], axis=0)\n",
    "\n",
    "df_results.to_csv(OUTPUT_PATH / f\"{P.name}_train_delay_results.csv\", index=False)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Results from \"Training set size\" evaluation & prepare for plotting:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(OUTPUT_PATH / f\"{P.name}_train_delay_results.csv\")\n",
    "df_plot = (\n",
    "    df_results[[\"test_eer\", \"owner\", \"train_samples\"]]\n",
    "    .groupby([\"owner\", \"train_samples\"], as_index=False)\n",
    "    .mean()\n",
    "    .astype({\"owner\": \"category\"})\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"test_eer\": \"Test EER\",\n",
    "            \"owner\": \"Owner\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df_plot[\"Training Data in Seconds\"] = df_plot[\"train_samples\"] * P.window_size / P.frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot EER with increasing number of training samples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_plot_training_delay(df_plot)\n",
    "utils_save_plot(plt, REPORT_PATH / f\"buech2019-ocsvm-{P.name.lower()}-train-size.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Evaluate increasing Test Set Sizes (Detection Delay)<a id='4.4'>&nbsp;</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = None  # Will be filled with cv scores\n",
    "for i in tqdm(range(20), desc=\"Run\", leave=False):\n",
    "    for df_cv_scenarios, owner, impostors in tqdm(\n",
    "        utils_generate_cv_scenarios(\n",
    "            df_train_test,\n",
    "            samples_per_subject_train=P.samples_per_subject_train,\n",
    "            samples_per_subject_test=P.samples_per_subject_test,\n",
    "            limit_test_samples=1,  # Samples overall\n",
    "            seed=SEED + i,  # Change seed for different runs\n",
    "            scaler=P.scaler,\n",
    "            scaler_global=P.scaler_global,\n",
    "            scaler_scope=P.scaler_scope,\n",
    "            feature_cols=P.feature_cols,\n",
    "        ),\n",
    "        desc=\"Owner\",\n",
    "        total=df_train_test[\"subject\"].nunique(),\n",
    "        leave=False,\n",
    "    ):\n",
    "        X = np.array(df_cv_scenarios[\"X\"].values.tolist())\n",
    "        X = X.reshape(X.shape[-3], -1)  # flatten windows\n",
    "        y = df_cv_scenarios[\"label\"].values\n",
    "        train_test_cv = utils_create_cv_splits(df_cv_scenarios[\"mask\"].values, SEED)\n",
    "\n",
    "        model = OneClassSVM(kernel=\"rbf\", nu=P.ocsvm_nu, gamma=P.ocsvm_gamma)\n",
    "\n",
    "        scores = cross_validate(\n",
    "            model,\n",
    "            X,\n",
    "            y,\n",
    "            cv=train_test_cv,\n",
    "            scoring={\"eer\": utils_eer_scorer},\n",
    "            n_jobs=CORES,\n",
    "            verbose=0,\n",
    "            return_train_score=True,\n",
    "        )\n",
    "        df_score = pd.DataFrame(scores)\n",
    "        df_score[\"owner\"] = owner\n",
    "        df_score[\"train_eer\"] = df_score[\"train_eer\"].abs()  # Revert scorer's signflip\n",
    "        df_score[\"test_eer\"] = df_score[\"test_eer\"].abs()\n",
    "        df_results = pd.concat([df_results, df_score], axis=0)\n",
    "\n",
    "df_results.to_csv(OUTPUT_PATH / f\"{P.name}_detect_delay_results.csv\", index=False)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Results from \"Detection Delay\" evaluation & prepare for plotting:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(OUTPUT_PATH / f\"{P.name}_detect_delay_results.csv\")\n",
    "df_results[\"owner\"] = df_results[\"owner\"].astype(str)\n",
    "df_plot = df_results.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Expanding Mean EER and confidence interval:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_plot_detect_delay(df_plot, factor=P.window_size / P.frequency, xlim=160)\n",
    "utils_save_plot(plt, REPORT_PATH / f\"buech2019-ocsvm-{P.name.lower()}-detection-delay.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
